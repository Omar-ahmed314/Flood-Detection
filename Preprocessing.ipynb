{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "G6gvCgiQwuNe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ========== ----- ========== Import Libraries ========== ----- ========== #\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Resize Images ========== ----- ========== #\n",
        "\n",
        "# If you want to resize all the images in the list to the same size, it's usually a good idea to choose a target size\n",
        "# that is smaller than the largest image in the list, but larger than the smallest image. This way, you can ensure that\n",
        "# all the images will be scaled down without losing too much detail or becoming too small.\n",
        "# For example, if the largest image has a size of(3072, 4592, 3) and the smallest image has a size of(155, 155, 3),\n",
        "# you could choose a target size of(512, 512, 3). This size should be large enough to capture most of the details in\n",
        "# the larger images while still being a significant improvement over the smaller images.\n",
        "\n",
        "# Set the path to your input and output directories\n",
        "input_dirs = ['dataset/flooded', 'dataset/non-flooded']\n",
        "\n",
        "img_sizes = []\n",
        "for input_dir in input_dirs:\n",
        "    # Loop through all the files in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        # Read the image from the input directory\n",
        "        img = cv2.imread(os.path.join(input_dir, filename))\n",
        "        img_sizes.append(img.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum size of flooded & non-flooded images:  (152, 123, 3)\n",
            "Maximuim size of flooded & non-flooded images:  (3072, 4592, 3) \n",
            "\n",
            "Target size of flooded & non-flooded images will be  (512, 512, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Minimum size of flooded & non-flooded images: \", min(img_sizes))\n",
        "print(\"Maximuim size of flooded & non-flooded images: \", max(img_sizes),\"\\n\")\n",
        "print(\"Target size of flooded & non-flooded images will be \", (512, 512, 3))\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Haze Removal Function ========== ----- ========== #\n",
        "\n",
        "def haze_Removal(img):\n",
        "    # The same pixels threshold for all (their histograms are alike)\n",
        "    threshold = 100\n",
        "\n",
        "    # Copy original image into a new image.\n",
        "    new_img = img.copy()\n",
        "\n",
        "    # Means we will shift by the first grey-level where there is less than 500 pixels\n",
        "    # This was set by judging from results and image size\n",
        "\n",
        "    for band_num in range(img.shape[2]):\n",
        "        # notice that min, max are called argmin and argmax here (since that's what they really are.)\n",
        "\n",
        "        img_band = img[:, :, band_num]\n",
        "        hist = cv2.calcHist([img_band], [0], None, [256], [0, 256])\n",
        "\n",
        "        # The first index (BV) where there is atleast \"threshold\" no. of pixels\n",
        "        argmin = np.where(hist > threshold)[0][0]\n",
        "\n",
        "        new_img_band = new_img[:, :, band_num]\n",
        "        \n",
        "        # To avoid shifting beyond zero\n",
        "        big_vals = new_img_band > argmin\n",
        "        new_img_band[big_vals] = new_img_band[big_vals] - argmin\n",
        "\n",
        "        new_img[:, :, band_num] = new_img_band\n",
        "    \n",
        "    return new_img\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ----- ========== Preprocessing Function ========== ----- ========== #\n",
        "\n",
        "# Set the path to your input and output directories\n",
        "output_dirs = ['dataset_preprocessed/flooded',\n",
        "               'dataset_preprocessed/non-flooded'\n",
        "               ]\n",
        "new_size = (512, 512)\n",
        "\n",
        "# Loop through all the files in the input directory\n",
        "for input_dir in input_dirs:\n",
        "    for filename in os.listdir(input_dir):\n",
        "\n",
        "        # Read the image from the input directory\n",
        "        img = cv2.imread(os.path.join(input_dir, filename))\n",
        "\n",
        "        # Resize the image to a desired size (e.g. 512*512)\n",
        "        img = cv2.resize(img, new_size)\n",
        "\n",
        "        # # Use bicubic interpolation to enhance the image resolution\n",
        "        img = cv2.resize(img, None, fx=1, fy=1, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # Apply Haze Removal by Dark Subtraction\n",
        "        img = haze_Removal(img)\n",
        "\n",
        "        # Save the processed image to the output directory\n",
        "        if (input_dir == 'dataset/flooded'):\n",
        "            cv2.imwrite(os.path.join(output_dirs[0], filename), img)\n",
        "        else:\n",
        "            cv2.imwrite(os.path.join(output_dirs[1], filename), img)\n",
        "\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DS_LDPcode.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "6bfa36d986fbc1c291755fa9731a4cbae79dd61283ac29a44ae53db584cd6a01"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
