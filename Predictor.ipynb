{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "O5tscwUa-eJt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jc2KlLo8ZiN",
        "outputId": "f269ddba-2ca9-4150-d541-e92feac2d410"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TestSetDir=\"/content/drive/MyDrive/Test\"\n",
        "CompetitionModelPath = \"/content/drive/MyDrive/Team21.pth\"\n",
        "ResultsPath = \"/content/drive/MyDrive/Team21.txt\""
      ],
      "metadata": {
        "id": "QCfs_4nNAUkX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING"
      ],
      "metadata": {
        "id": "OTlOmsBC-wGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ProcessedTestSetDir = \"/content/drive/MyDrive/Team21Preprocessed\"\n",
        "\n",
        "if not os.path.exists(ProcessedTestSetDir):\n",
        "  os.mkdir(ProcessedTestSetDir)"
      ],
      "metadata": {
        "id": "OE1cQXyw-kgn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def haze_Removal(img):\n",
        "    # The same pixels threshold for all (their histograms are alike)\n",
        "    threshold = 100\n",
        "\n",
        "    # Copy original image into a new image.\n",
        "    new_img = img.copy()\n",
        "\n",
        "    # Means we will shift by the first grey-level where there is less than 500 pixels\n",
        "    # This was set by judging from results and image size\n",
        "\n",
        "    for band_num in range(img.shape[2]):\n",
        "        # notice that min, max are called argmin and argmax here (since that's what they really are.)\n",
        "\n",
        "        img_band = img[:, :, band_num]\n",
        "        hist = cv2.calcHist([img_band], [0], None, [256], [0, 256])\n",
        "\n",
        "        # The first index (BV) where there is atleast \"threshold\" no. of pixels\n",
        "        argmin = np.where(hist > threshold)[0][0]\n",
        "\n",
        "        new_img_band = new_img[:, :, band_num]\n",
        "        \n",
        "        # To avoid shifting beyond zero\n",
        "        big_vals = new_img_band > argmin\n",
        "        new_img_band[big_vals] = new_img_band[big_vals] - argmin\n",
        "\n",
        "        new_img[:, :, band_num] = new_img_band\n",
        "    \n",
        "    return new_img"
      ],
      "metadata": {
        "id": "yeBXs4pL_OqC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your input and output directories\n",
        "new_size = (256, 256)\n",
        "\n",
        "testing_images = []\n",
        "\n",
        "# Loop through all the files in the input directory\n",
        "\n",
        "files = os.listdir(TestSetDir)\n",
        "sorted_files = sorted(files, key=lambda x: int(x.split(\".\")[0]))\n",
        "\n",
        "for filename in sorted_files:\n",
        "    print(filename)\n",
        "\n",
        "    # Read the image from the input directory\n",
        "    img = cv2.imread(os.path.join(TestSetDir, filename))\n",
        "\n",
        "    # Resize the image to a desired size (e.g. 512*512)\n",
        "    img = cv2.resize(img, new_size)\n",
        "\n",
        "    # # Use bicubic interpolation to enhance the image resolution\n",
        "    img = cv2.resize(img, None, fx=1, fy=1, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Apply Haze Removal by Dark Subtraction\n",
        "    img = haze_Removal(img)\n",
        "\n",
        "    testing_images.append(img)\n",
        "\n",
        "    # Save the processed image to the output directory\n",
        "    #cv2.imwrite(os.path.join(ProcessedTestSetDir, filename), img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3qdYebc_VGi",
        "outputId": "1f8cc396-458d-4bc9-ca24-68000083e5aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.jpg\n",
            "1.jpg\n",
            "2.jpg\n",
            "3.jpg\n",
            "4.jpg\n",
            "5.jpg\n",
            "6.jpg\n",
            "7.jpg\n",
            "8.jpg\n",
            "9.jpg\n",
            "10.jpg\n",
            "11.jpg\n",
            "12.jpg\n",
            "13.jpg\n",
            "578.jpg\n",
            "579.jpg\n",
            "580.jpg\n",
            "581.jpg\n",
            "582.jpg\n",
            "583.jpg\n",
            "584.jpg\n",
            "585.jpg\n",
            "586.jpg\n",
            "587.jpg\n",
            "588.jpg\n",
            "589.jpg\n",
            "590.jpg\n",
            "591.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "n65fm2T7BfGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the last layer for 2 classes only\n",
        "features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(features, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-REeFdo1BKXJ",
        "outputId": "0e52a075-413b-4de9-ccfc-5ec5362e84e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "Q7eXwe4jBdT-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cMlYW0Us69Cc"
      },
      "outputs": [],
      "source": [
        "model = resnet50\n",
        "model.load_state_dict(torch.load(CompetitionModelPath))\n",
        "model.eval()\n",
        "\n",
        "means= [0.3337701, 0.35129565, 0.36801142]\n",
        "stds= [0.16881385, 0.1562263, 0.16852096]\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((256,256)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((means[0],means[1],means[2]), (stds[0],stds[1],stds[2]))])\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for image in testing_images:\n",
        "    image = Image.fromarray(image)\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "    \n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    _, predicted_label = torch.max(probs.data, 1)\n",
        "\n",
        "    predictions.append(predicted_label.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalPreds = []\n",
        "for pred in predictions:\n",
        "  if pred == 1:\n",
        "    finalPreds.append(0)\n",
        "  else:\n",
        "    finalPreds.append(1)"
      ],
      "metadata": {
        "id": "2z4zsB6pEkJB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(ResultsPath, 'w') as file:\n",
        "    for label in finalPreds:\n",
        "        file.write(str(label) + '\\n')"
      ],
      "metadata": {
        "id": "JvgkVGtiNDQS"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}