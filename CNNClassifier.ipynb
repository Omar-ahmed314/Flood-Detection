{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mEXpCSS3f1Dq"
      },
      "source": [
        "Example of building a simple CNN for CIFAR10 dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_dir = 'dataset_preprocessed'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #calculate means and std to be used with normalization\n",
        "# dataset = ImageFolder(dataset_dir, transform=ToTensor())\n",
        "\n",
        "# # Compute mean and standard deviation\n",
        "# means = []\n",
        "# stds = []\n",
        "# for img, _ in dataset:\n",
        "#     means.append(img.mean(dim=(1,2)))\n",
        "#     stds.append(img.std(dim=(1,2)))\n",
        "\n",
        "# means = np.stack(means).mean(axis=0)\n",
        "# stds = np.stack(stds).mean(axis=0)\n",
        "\n",
        "# print(f\"Means: {means}\")\n",
        "# print(f\"Stds: {stds}\")\n",
        "\n",
        "means= [0.3337701, 0.35129565, 0.36801142]\n",
        "stds= [0.16881385, 0.1562263, 0.16852096]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ammar\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ammar\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\ammar/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:28<00:00, 3.54MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Load resnet50 and freeze\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the last layer for 2 classes only\n",
        "features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(features, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Creates a data transformation pipeline using the transforms.Compose function from the PyTorch library.\n",
        "\n",
        "\"\"\"\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((256,256)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((means[0],means[1],means[2]), (stds[0],stds[1],stds[2]))])\n",
        "\n",
        "# Load the training and validation datasets in folder 'dataset'\n",
        "full_data = ImageFolder(dataset_dir, transform=transform)\n",
        "\n",
        "#Split the dataset\n",
        "train_size = int(0.85 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "trainDataset, testDataset = torch.utils.data.random_split(full_data, [train_size, test_size])\n",
        "\n",
        "# Create DataLoader objects to iterate over the datasets in batches\n",
        "trainloader = torch.utils.data.DataLoader(trainDataset, batch_size=32, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testDataset, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,     5] loss: 0.645\n",
            "[1,    10] loss: 0.554\n",
            "[1,    15] loss: 0.478\n",
            "[1,    20] loss: 0.381\n",
            "[1,    25] loss: 0.335\n",
            "Epoch 1/10, Train Acc: 77.01%\n",
            "[2,     5] loss: 0.310\n",
            "[2,    10] loss: 0.259\n",
            "[2,    15] loss: 0.261\n",
            "[2,    20] loss: 0.312\n",
            "[2,    25] loss: 0.244\n",
            "Epoch 2/10, Train Acc: 91.95%\n",
            "[3,     5] loss: 0.209\n",
            "[3,    10] loss: 0.169\n",
            "[3,    15] loss: 0.262\n",
            "[3,    20] loss: 0.227\n",
            "[3,    25] loss: 0.240\n",
            "Epoch 3/10, Train Acc: 93.10%\n",
            "[4,     5] loss: 0.163\n",
            "[4,    10] loss: 0.141\n",
            "[4,    15] loss: 0.171\n",
            "[4,    20] loss: 0.191\n",
            "[4,    25] loss: 0.166\n",
            "Epoch 4/10, Train Acc: 95.02%\n",
            "[5,     5] loss: 0.242\n",
            "[5,    10] loss: 0.179\n",
            "[5,    15] loss: 0.202\n",
            "[5,    20] loss: 0.127\n",
            "[5,    25] loss: 0.141\n",
            "Epoch 5/10, Train Acc: 94.25%\n",
            "[6,     5] loss: 0.154\n",
            "[6,    10] loss: 0.123\n",
            "[6,    15] loss: 0.188\n",
            "[6,    20] loss: 0.141\n",
            "[6,    25] loss: 0.147\n",
            "Epoch 6/10, Train Acc: 95.66%\n",
            "[7,     5] loss: 0.122\n",
            "[7,    10] loss: 0.155\n",
            "[7,    15] loss: 0.082\n",
            "[7,    20] loss: 0.124\n",
            "[7,    25] loss: 0.147\n",
            "Epoch 7/10, Train Acc: 96.30%\n",
            "[8,     5] loss: 0.126\n",
            "[8,    10] loss: 0.105\n",
            "[8,    15] loss: 0.146\n",
            "[8,    20] loss: 0.129\n",
            "[8,    25] loss: 0.125\n",
            "Epoch 8/10, Train Acc: 96.42%\n",
            "[9,     5] loss: 0.148\n",
            "[9,    10] loss: 0.123\n",
            "[9,    15] loss: 0.113\n",
            "[9,    20] loss: 0.082\n",
            "[9,    25] loss: 0.129\n",
            "Epoch 9/10, Train Acc: 96.30%\n",
            "[10,     5] loss: 0.147\n",
            "[10,    10] loss: 0.128\n",
            "[10,    15] loss: 0.093\n",
            "[10,    20] loss: 0.117\n",
            "[10,    25] loss: 0.085\n",
            "Epoch 10/10, Train Acc: 97.19%\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "net = resnet50\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the network\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 5 == 4:    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 5))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    train_acc = 100.0 * correct / total\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Acc: {train_acc:.2f}%')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the network on the test data\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 139 test images: 94 %\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy of the network on the '+str(test_size)+' test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save the trained model\n",
        "PATH = './floodFinal.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "9\n",
            "10\n",
            "Accuracy of the network on the 139 test images: 90 %\n"
          ]
        }
      ],
      "source": [
        "#Testing on random images from internet\n",
        "\n",
        "# model = resnet50\n",
        "# model.load_state_dict(torch.load('floodFinal.pth'))\n",
        "# model.eval()\n",
        "\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [\n",
        "#      transforms.Resize((256,256)),\n",
        "#      transforms.ToTensor(),\n",
        "#      transforms.Normalize((means[0],means[1],means[2]), (stds[0],stds[1],stds[2]))])\n",
        "\n",
        "# full_data = ImageFolder('data', transform=transform)\n",
        "\n",
        "# testloader = torch.utils.data.DataLoader(full_data, batch_size=32)\n",
        "\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# with torch.no_grad():\n",
        "#     for data in testloader:\n",
        "#         images, labels = data\n",
        "#         print(labels)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         print(predicted)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print(correct)\n",
        "# print(total)\n",
        "\n",
        "# print('Accuracy of the network on the '+str(test_size)+' test images: %d %%' % (\n",
        "#     100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
