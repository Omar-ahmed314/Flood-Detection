{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mEXpCSS3f1Dq"
      },
      "source": [
        "Example of building a simple CNN for CIFAR10 dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_dir = 'dataset_preprocessed'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #calculate means and std to be used with normalization\n",
        "# dataset = ImageFolder(dataset_dir, transform=ToTensor())\n",
        "\n",
        "# # Compute mean and standard deviation\n",
        "# means = []\n",
        "# stds = []\n",
        "# for img, _ in dataset:\n",
        "#     means.append(img.mean(dim=(1,2)))\n",
        "#     stds.append(img.std(dim=(1,2)))\n",
        "\n",
        "# means = np.stack(means).mean(axis=0)\n",
        "# stds = np.stack(stds).mean(axis=0)\n",
        "\n",
        "# print(f\"Means: {means}\")\n",
        "# print(f\"Stds: {stds}\")\n",
        "\n",
        "means= [0.3337701, 0.35129565, 0.36801142]\n",
        "stds= [0.16881385, 0.1562263, 0.16852096]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load resnet50 and freeze\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the last layer for 2 classes only\n",
        "features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(features, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Creates a data transformation pipeline using the transforms.Compose function from the PyTorch library.\n",
        "\n",
        "\"\"\"\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((256,256)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((means[0],means[1],means[2]), (stds[0],stds[1],stds[2]))])\n",
        "\n",
        "# Load the training and validation datasets in folder 'dataset'\n",
        "full_data = ImageFolder(dataset_dir, transform=transform)\n",
        "\n",
        "#Split the dataset\n",
        "train_size = int(0.85 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "torch.manual_seed(13)\n",
        "trainDataset, testDataset = torch.utils.data.random_split(full_data, [train_size, test_size])\n",
        "\n",
        "# Create DataLoader objects to iterate over the datasets in batches\n",
        "trainloader = torch.utils.data.DataLoader(trainDataset, batch_size=32, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testDataset, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,     5] loss: 0.728\n",
            "[1,    10] loss: 0.533\n",
            "[1,    15] loss: 0.526\n",
            "[1,    20] loss: 0.418\n",
            "[1,    25] loss: 0.353\n",
            "Epoch 1/10, Train Acc: 73.18%\n",
            "[2,     5] loss: 0.314\n",
            "[2,    10] loss: 0.269\n",
            "[2,    15] loss: 0.217\n",
            "[2,    20] loss: 0.256\n",
            "[2,    25] loss: 0.248\n",
            "Epoch 2/10, Train Acc: 92.85%\n",
            "[3,     5] loss: 0.217\n",
            "[3,    10] loss: 0.240\n",
            "[3,    15] loss: 0.268\n",
            "[3,    20] loss: 0.176\n",
            "[3,    25] loss: 0.190\n",
            "Epoch 3/10, Train Acc: 94.00%\n",
            "[4,     5] loss: 0.185\n",
            "[4,    10] loss: 0.193\n",
            "[4,    15] loss: 0.143\n",
            "[4,    20] loss: 0.153\n",
            "[4,    25] loss: 0.209\n",
            "Epoch 4/10, Train Acc: 95.40%\n",
            "[5,     5] loss: 0.208\n",
            "[5,    10] loss: 0.150\n",
            "[5,    15] loss: 0.146\n",
            "[5,    20] loss: 0.186\n",
            "[5,    25] loss: 0.140\n",
            "Epoch 5/10, Train Acc: 96.17%\n",
            "[6,     5] loss: 0.173\n",
            "[6,    10] loss: 0.181\n",
            "[6,    15] loss: 0.195\n",
            "[6,    20] loss: 0.133\n",
            "[6,    25] loss: 0.125\n",
            "Epoch 6/10, Train Acc: 94.76%\n",
            "[7,     5] loss: 0.213\n",
            "[7,    10] loss: 0.179\n",
            "[7,    15] loss: 0.361\n",
            "[7,    20] loss: 0.288\n",
            "[7,    25] loss: 0.153\n",
            "Epoch 7/10, Train Acc: 89.91%\n",
            "[8,     5] loss: 0.159\n",
            "[8,    10] loss: 0.158\n",
            "[8,    15] loss: 0.152\n",
            "[8,    20] loss: 0.208\n",
            "[8,    25] loss: 0.108\n",
            "Epoch 8/10, Train Acc: 94.64%\n",
            "[9,     5] loss: 0.149\n",
            "[9,    10] loss: 0.132\n",
            "[9,    15] loss: 0.068\n",
            "[9,    20] loss: 0.156\n",
            "[9,    25] loss: 0.110\n",
            "Epoch 9/10, Train Acc: 96.68%\n",
            "[10,     5] loss: 0.126\n",
            "[10,    10] loss: 0.121\n",
            "[10,    15] loss: 0.063\n",
            "[10,    20] loss: 0.149\n",
            "[10,    25] loss: 0.149\n",
            "Epoch 10/10, Train Acc: 95.91%\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "net = resnet50\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the network\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 5 == 4:    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 5))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    train_acc = 100.0 * correct / total\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Acc: {train_acc:.2f}%')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the network on the test data\n",
        "correct = 0\n",
        "total = 0\n",
        "y_test = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        y_test.extend(labels)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_pred.extend(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 139 test images: 96 %\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy of the network on the '+str(test_size)+' test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save the trained model\n",
        "PATH = './floodFinal.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[68,  2],\n",
              "       [ 3, 66]], dtype=int64)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        70\n",
            "           1       0.97      0.96      0.96        69\n",
            "\n",
            "    accuracy                           0.96       139\n",
            "   macro avg       0.96      0.96      0.96       139\n",
            "weighted avg       0.96      0.96      0.96       139\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "9\n",
            "10\n",
            "Accuracy of the network on the 139 test images: 90 %\n"
          ]
        }
      ],
      "source": [
        "#Testing on random images from internet\n",
        "\n",
        "# model = resnet50\n",
        "# model.load_state_dict(torch.load('floodFinal.pth'))\n",
        "# model.eval()\n",
        "\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [\n",
        "#      transforms.Resize((256,256)),\n",
        "#      transforms.ToTensor(),\n",
        "#      transforms.Normalize((means[0],means[1],means[2]), (stds[0],stds[1],stds[2]))])\n",
        "\n",
        "# full_data = ImageFolder('data', transform=transform)\n",
        "\n",
        "# testloader = torch.utils.data.DataLoader(full_data, batch_size=32)\n",
        "\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# with torch.no_grad():\n",
        "#     for data in testloader:\n",
        "#         images, labels = data\n",
        "#         print(labels)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         print(predicted)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print(correct)\n",
        "# print(total)\n",
        "\n",
        "# print('Accuracy of the network on the '+str(test_size)+' test images: %d %%' % (\n",
        "#     100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
